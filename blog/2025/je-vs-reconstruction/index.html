<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Joint-Embedding vs Reconstruction: When Should You Use Each? | Hugues Van Assel </title> <meta name="author" content="Hugues Van Assel"> <meta name="description" content="A theoretical analysis revealing when joint-embedding methods outperform reconstruction-based SSL, and vice versa."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://huguesva.github.io/blog/2025/je-vs-reconstruction/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js" integrity="sha256-rjmgmaB99riUNcdlrDtcAiwtLIojSxNyUFdl+Qh+rB4=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "Joint-Embedding vs Reconstruction: When Should You Use Each?",
            "description": "A theoretical analysis revealing when joint-embedding methods outperform reconstruction-based SSL, and vice versa.",
            "published": "November 20, 2025",
            "authors": [
              
              {
                "author": "Hugues Van Assel",
                "authorURL": "https://huguesva.github.io/",
                "affiliations": [
                  {
                    "name": "Genentech & Brown University",
                    "url": ""
                  }
                ]
              }
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Hugues</span> Van Assel </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/talks/">talks </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>Joint-Embedding vs Reconstruction: When Should You Use Each?</h1> <p>A theoretical analysis revealing when joint-embedding methods outperform reconstruction-based SSL, and vice versa.</p> </d-title> <d-byline></d-byline> <d-article> <script type="text/javascript" async="" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"> </script> <p>This blog post presents the key findings from our NeurIPS 2025 paper on comparing two fundamental paradigms in Self-Supervised Learning (SSL): <strong>reconstruction-based</strong> and <strong>joint-embedding</strong> methods.</p> <h2 id="introduction-two-paradigms-of-ssl">Introduction: Two Paradigms of SSL</h2> <p>Self-Supervised Learning has emerged as a powerful alternative to supervised learning, moving away from specialized labels toward specifying which variations should be disregarded. Two primary families of methods have emerged to learn representations using this principle:</p> <h3 id="reconstruction-based-approaches">Reconstruction-Based Approaches</h3> <p><strong>Reconstruction</strong>-based approaches train models by augmenting an input signal (e.g., adding noise or masking) and then training the model to restore the original input. This process encourages the model to learn meaningful internal representations of the data’s underlying structure. However, because the learning signal arises from minimizing reconstruction error in the input space, the model is naturally steered toward subspaces that explain the majority of the input’s variance.</p> <p>In <strong>language</strong>, reconstruction-based learning is highly effective because textual tokens represent compact, semantically meaningful units. Predicting a missing token provides a learning signal that operates directly in semantic space.</p> <p>In <strong>vision</strong>, however, variance-explaining features often emphasize aspects that are statistically dominant but semantically shallow. Pixel-level reconstruction objectives tend to drive models toward capturing local statistics and textures rather than higher-order structures and object-level relationships.</p> <h3 id="joint-embedding-approaches">Joint-Embedding Approaches</h3> <p><strong>Joint-embedding</strong> methods operate entirely in latent space. Their objective is to produce similar representations for different augmented views of the same input while ensuring that representations of distinct samples remain dissimilar. This separation can be enforced explicitly through a contrastive loss, or implicitly via architectural mechanisms such as self-distillation, stop-gradient operations, or predictor heads.</p> <p>Unlike reconstruction-based approaches, joint-embedding methods do not predict in the input space and are therefore <strong>less biased toward capturing high-variance components</strong> of the signal. Empirically, joint-embedding frameworks have shown strong performance across domains where the input signal is high-dimensional and semantically diffuse, including histopathology, Earth observation, and video representation learning.</p> <div style="text-align: center; margin: 2em 0;"> <img src="/assets/img/blog-je-vs-rc/schema_je_vs_reconstruction.png" alt="SSL paradigms comparison" style="width: 95%; max-width: 900px;"> <p style="font-size: 0.9em; color: #666; margin-top: 0.5em;"> <strong>Figure 1:</strong> Two self-supervised learning paradigms. <em>Left:</em> Reconstruction approach trains an encoder $f_{\mathbf{E}}$ and decoder $f_{\mathbf{D}}$ to recover $\mathbf{x}$ from augmented view $\tau(\mathbf{x})$. <em>Right:</em> Joint-embedding approach maps two independent augmentations $\tau_1(\mathbf{x})$ and $\tau_2(\mathbf{x})$ to nearby representations via $f_{\mathbf{W}}$. </p> </div> <h2 id="the-two-main-problems-and-their-solutions">The Two Main Problems and Their Solutions</h2> <p>Consider \(n\) samples \(\mathbf{X} = (\mathbf{x}_1, \dots, \mathbf{x}_n)^\top \in \mathbb{R}^{n \times d}\) and a data augmentation distribution \(\mathcal{T}\) defined over transformations \(\tau: \mathbb{R}^d \rightarrow \mathbb{R}^d\). For analytical tractability, we focus on linear models: \(f_{\mathbf{E}}: \mathbf{x} \mapsto \mathbf{E} \mathbf{x}\), \(f_{\mathbf{D}}: \mathbf{z} \mapsto \mathbf{D} \mathbf{z}\), and \(f_{\mathbf{W}}: \mathbf{x} \mapsto \mathbf{W} \mathbf{x}\).</p> <h3 id="problem-1-reconstruction-based-ssl">Problem 1: Reconstruction-Based SSL</h3> <p>The reconstruction problem is formulated as:</p> \[\begin{align}\tag{SSL-RC}\label{eq:reconstruction} \min_{\mathbf{E}, \mathbf{D}} \quad \frac{1}{n} \sum_{i=1}^{n} \mathbb{E}_{\tau \sim \mathcal{T}} \left[ \| \mathbf{x}_i - f_\mathbf{D}(f_\mathbf{E}(\tau(\mathbf{x}_i))) \|_2^2 \right] \end{align}\] <p>where \(f_{\mathbf{E}}\) and \(f_{\mathbf{D}}\) are encoder and decoder functions. Each data sample is augmented, encoded, and decoded, with the objective to minimize reconstruction error. This methodology is analogous to Denoising Auto-Encoders and Masked Auto-Encoders (MAE).</p> <details><summary>Closed-Form Solution for Reconstruction</summary> <p><strong>Theorem 1 (Reconstruction-Based SSL).</strong> Let \(\overline{\mathbf{x}}_i := \mathbb{E}_{\tau \sim \mathcal{T}}[\tau(\mathbf{x}_i)]\) denote the expected augmented sample and \(\overline{\mathbf{X}} := (\overline{\mathbf{x}}_1, \dots, \overline{\mathbf{x}}_n)^\top\). Define the covariance of augmented samples:</p> \[\mathbf{\Sigma} := \frac{1}{n} \sum_{i} \mathbb{E}_{\tau \sim \mathcal{T}} \left[ \tau(\mathbf{x}_i) \tau(\mathbf{x}_i)^\top\right] - \mathbb{E}_{\tau \sim \mathcal{T}} \left[\tau(\mathbf{x}_i) \right] \mathbb{E}_{\tau \sim \mathcal{T}} \left[\tau(\mathbf{x}_i) \right]^\top\] <p>Assume that \(\frac{1}{n} \overline{\mathbf{X}}^\top \overline{\mathbf{X}} + \mathbf{\Sigma}\) is positive definite. Consider the singular value decomposition:</p> \[\begin{align} \frac{1}{n} \mathbf{X}^\top \overline{\mathbf{X}} \left(\frac{1}{n} \overline{\mathbf{X}}^\top \overline{\mathbf{X}} + \mathbf{\Sigma} \right)^{-\frac{1}{2}} = \mathbf{R} \mathbf{\Phi} \mathbf{P}^\top \end{align}\] <p>where \(\mathbf{R} \in \mathbb{R}^{d \times d}\) and \(\mathbf{P} \in \mathbb{R}^{d \times d}\) are orthogonal and \(\mathbf{\Phi} := \mathrm{diag}(\phi_1, \dots, \phi_d)\) with \(\phi_1 \geq \dots \geq \phi_d \geq 0\).</p> <p>Solutions of the reconstruction problem \eqref{eq:reconstruction} take the form:</p> \[\begin{align} \mathbf{E}^\star = \mathbf{T} \mathbf{P}_k^\top \left(\frac{1}{n} \overline{\mathbf{X}}^\top \overline{\mathbf{X}} + \mathbf{\Sigma} \right)^{-\frac{1}{2}} \quad \text{and} \quad \mathbf{D}^\star = \mathbf{R}_k \mathbf{\Phi}_k \mathbf{T}^{-1} \end{align}\] <p>where \(\mathbf{T}\) is any invertible matrix in \(\mathbb{R}^{k \times k}\), \(\mathbf{P}_k\) and \(\mathbf{R}_k\) are the first \(k\) columns of \(\mathbf{P}\) and \(\mathbf{R}\), and \(\mathbf{\Phi}_k = \mathrm{diag}(\phi_1, \dots, \phi_k)\).</p> </details> <h3 id="problem-2-joint-embedding-based-ssl">Problem 2: Joint-Embedding-Based SSL</h3> <p>The joint-embedding problem is formulated as:</p> \[\begin{equation}\tag{SSL-JE}\label{eq:ssl} \begin{aligned} \min_{\mathbf{W}} \quad &amp; \frac{1}{n} \sum_{i=1}^{n} \mathbb{E}_{\tau_1, \tau_2 \sim \mathcal{T}} \left[ \| f_\mathbf{W}(\tau_1(\mathbf{x}_i)) - f_\mathbf{W}(\tau_2(\mathbf{x}_i)) \|^2_2 \right] \\ \text{subject to} \quad &amp; \frac{1}{n} \sum_{i=1}^{n} \mathbb{E}_{\tau \sim \mathcal{T}} \left[ f_\mathbf{W}(\tau(\mathbf{x}_i)) f_\mathbf{W}(\tau(\mathbf{x}_i))^\top\right] = \mathbf{I}_k \end{aligned} \end{equation}\] <p>where \(f_{\mathbf{W}}\) is the SSL model. The objective represents the invariance term ensuring consistency between augmented views, while the constraint enforces orthonormality, preventing collapse. This formulation closely resembles methods like SimCLR, VICReg, BYOL, and DINO.</p> <details><summary>Closed-Form Solution for Joint-Embedding</summary> <p><strong>Theorem 2 (Joint-Embedding-Based SSL).</strong> Let \(\mathbf{S} := \frac{1}{n} \sum_{i} \mathbb{E}_{\tau \sim \mathcal{T}} \left[ \tau(\mathbf{x}_i) \tau(\mathbf{x}_i)^\top\right]\) and \(\mathbf{G} := \frac{1}{n} \sum_{i} \mathbb{E}_{\tau \sim \mathcal{T}} \left[ \tau(\mathbf{x}_i)\right] \mathbb{E}_{\tau \sim \mathcal{T}} \left[ \tau(\mathbf{x}_i)\right]^\top\).</p> <p>Assume that \(\mathbf{S}\) is positive definite. Consider the eigendecomposition:</p> \[\begin{align} \mathbf{S}^{-\frac{1}{2}} \mathbf{G} \mathbf{S}^{-\frac{1}{2}} = \mathbf{Q} \mathbf{\Omega} \mathbf{Q}^\top \end{align}\] <p>where \(\mathbf{\Omega} = \mathrm{diag}(\omega_1, \dots, \omega_d)\) with \(\omega_1 \geq \dots \geq \omega_d\).</p> <p>Solutions of the joint-embedding problem \eqref{eq:ssl} take the form:</p> \[\begin{align} \mathbf{W}^\star = \mathbf{U} \mathbf{Q}_k^\top \mathbf{S}^{-\frac{1}{2}} \end{align}\] <p>where \(\mathbf{Q}_k = (\mathbf{q}_1, \dots, \mathbf{q}_k)\) and \(\mathbf{U}\) is any orthogonal matrix of size \(k \times k\).</p> </details> <p>These closed-form solutions are directly parameterized by the augmentation structure, enabling us to analyze precisely how augmentations impact learned representations.</p> <h2 id="key-findings-augmentation-alignment-requirements">Key Findings: Augmentation Alignment Requirements</h2> <p>Using these closed-form solutions, we uncover fundamental differences between the two paradigms. We model data as having \(k\) <strong>important signal components</strong> and \(d-k\) <strong>pure noise components</strong> (irrelevant features that SSL should be invariant to). Optimal performance is achieved when the learned representations discard these irrelevant features and retain only the important, meaningful signal components.</p> <p>We introduce a parameter \(\alpha \geq 0\) that controls the <strong>alignment</strong> between the irrelevant features and the augmentations. Our main theoretical results reveal:</p> <h3 id="finding-1-ssl-requires-aligned-augmentations">Finding 1: SSL Requires Aligned Augmentations</h3> <p>Unlike supervised learning, <strong>both SSL paradigms require aligned augmentations to achieve optimal performance</strong>, even with infinite samples. Simply increasing the sample size cannot overcome misalignment between augmentations and noise.</p> <div style="background-color: #f5f5f5; border-left: 4px solid #9C27B0; padding: 0.8em; margin: 1em 0;"> <strong>Proposition (Supervised Learning).</strong> Supervised models achieve optimal performance either when: <ul style="margin: 0.3em 0; padding-left: 1.5em;"> <li>Augmentations are well aligned with noise ($\alpha$ large), or</li> <li>Sample size is large ($n \to \infty$), <strong>regardless of alignment</strong>.</li> </ul> </div> <div style="background-color: #f5f5f5; border-left: 4px solid #9C27B0; padding: 0.8em; margin: 1em 0;"> <strong>Proposition (Self-Supervised Learning).</strong> SSL models achieve optimal performance when: <ul style="margin: 0.3em 0; padding-left: 1.5em;"> <li>Augmentations are well aligned with noise ($\alpha$ large), or</li> <li>Sample size is large ($n \to \infty$) <strong>AND</strong> alignment satisfies $\alpha &gt; \alpha_{\text{threshold}}$.</li> </ul> </div> <p>This critical difference underscores that <strong>carefully designed augmentations are essential in SSL</strong>.</p> <h3 id="finding-2-joint-embedding-vs-reconstruction-comparison">Finding 2: Joint-Embedding vs Reconstruction Comparison</h3> <p>Having established that SSL requires aligned augmentations, we now compare the two SSL paradigms. Our second major finding reveals when to prefer each paradigm. Recall that both methods require the alignment parameter $\alpha$ to exceed a certain threshold to achieve optimal performance. Crucially, <strong>these thresholds differ</strong> between the two paradigms:</p> <ul> <li> <strong>Reconstruction</strong> has threshold $\alpha_{\text{RC}}$</li> <li> <strong>Joint-embedding</strong> has threshold $\alpha_{\text{JE}}$</li> </ul> <p>These thresholds depend on noise magnitude, augmentation quality, and data characteristics. <strong>A smaller threshold is preferable</strong> as it succeeds in more scenarios: since we don’t know noise characteristics in advance, lower alignment requirements mean greater robustness.</p> <p>Our analysis reveals:</p> <div style="background-color: #f5f5f5; border-left: 4px solid #4CAF50; padding: 0.8em; margin: 1em 0;"> <strong>Low-Magnitude Irrelevant Features:</strong> When noise/irrelevant features have small variance, reconstruction requires less alignment: $\alpha_{\text{RC}} &lt; \alpha_{\text{JE}}$ <br><strong>→ Reconstruction is preferable</strong> </div> <div style="background-color: #f5f5f5; border-left: 4px solid #FF5722; padding: 0.8em; margin: 1em 0;"> <strong>High-Magnitude Irrelevant Features:</strong> When noise/irrelevant features have large variance, joint-embedding requires less alignment: $\alpha_{\text{JE}} &lt; \alpha_{\text{RC}}$ <br><strong>→ Joint-embedding is preferable</strong> </div> <h3 id="interpretation">Interpretation</h3> <p><strong>Reconstruction</strong> methods prioritize high-variance components: with low-magnitude noise, important features dominate naturally. In contrast, <strong>joint-embedding</strong> methods operate in latent space, bypassing the need to reconstruct noisy components. With high-magnitude noise, they require less alignment because they avoid reconstructing irrelevant features.</p> <p>Since data from physical world measurements (images, sounds, sensor recordings) often contain high-magnitude irrelevant features (backgrounds, experimental artifacts), <strong>joint-embedding is typically more robust in practice</strong>. Our experiments on ImageNet-1k confirm this: joint-embedding methods like DINO and BYOL are considerably more robust to severe data corruption than reconstruction-based methods like MAE.</p> <div style="text-align: center; margin: 2em 0;"> <img src="/assets/img/blog-je-vs-rc/mnist_small.png" alt="Linear models validation" style="width: 100%; max-width: 1000px;"> <p style="font-size: 0.9em; color: #666; margin-top: 0.5em;"> <strong>Figure 2:</strong> Validation on linear models with MNIST corrupted by synthetic Gaussian noise. Each subplot shows how performance varies with sample size $n$ (x-axis) and augmentation alignment $\alpha$ (different lines). <em>Left:</em> Supervised learning achieves optimal performance with either large $n$ or large $\alpha$, regardless of noise magnitude. <em>Middle:</em> Joint-embedding requires minimal alignment but remains robust even with strong noise. <em>Right:</em> Reconstruction is robust to augmentation choice under weak noise but degrades under strong noise. </p> </div> <h2 id="practical-takeaway">Practical Takeaway</h2> <div style="background-color: #e3f2fd; border-left: 4px solid #2196F3; padding: 1em; margin: 2em 0;"> <strong>Key Recommendation:</strong> <ul style="margin: 0.5em 0;"> <li> <strong>Use Reconstruction</strong> when irrelevant features have low magnitude and you have limited knowledge about effective augmentations.</li> <li> <strong>Use Joint-Embedding</strong> when irrelevant features are non-negligible (common in physical world measurements) or when effective augmentations can be identified.</li> </ul> </div> <p>For more technical details, proofs, and comprehensive experimental results, please refer to our <a href="https://arxiv.org/abs/2505.12477" rel="external nofollow noopener" target="_blank">full paper</a>.</p> <h2 id="citation">Citation</h2> <p>If you found this work useful, please cite our NeurIPS 2025 paper:</p> <div class="language-bibtex highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">vanassel2025je</span><span class="p">,</span>
  <span class="na">title</span><span class="p">=</span><span class="s">{Joint-Embedding vs Reconstruction: Provable Benefits of Latent Space Prediction for Self-Supervised Learning}</span><span class="p">,</span>
  <span class="na">author</span><span class="p">=</span><span class="s">{Van Assel, Hugues and Ibrahim, Mark and Biancalani, Tommaso and Regev, Aviv and Balestriero, Randall}</span><span class="p">,</span>
  <span class="na">booktitle</span><span class="p">=</span><span class="s">{Advances in Neural Information Processing Systems}</span><span class="p">,</span>
  <span class="na">year</span><span class="p">=</span><span class="s">{2025}</span>
<span class="p">}</span>
</code></pre></div></div> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/"></d-bibliography> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Hugues Van Assel. </div> </footer> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-QD8W0160XJ"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-QD8W0160XJ");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> </body> </html>