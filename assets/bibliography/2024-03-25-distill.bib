@inproceedings{chowdhury2021generalized,
  title={Generalized spectral clustering via Gromov-Wasserstein learning},
  author={Chowdhury, Samir and Needham, Tom},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={712--720},
  year={2021},
  organization={PMLR}
}

@InProceedings{pmlr-v202-chen23ak,
  title = 	 {A Gromov-{W}asserstein Geometric View of Spectrum-Preserving Graph Coarsening},
  author =       {Chen, Yifan and Yao, Rentian and Yang, Yun and Chen, Jie},
  booktitle = 	 {Proceedings of the 40th International Conference on Machine Learning},
  pages = 	 {5257--5281},
  year = 	 {2023},
  editor = 	 {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
  volume = 	 {202},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {23--29 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v202/chen23ak/chen23ak.pdf},
  url = 	 {https://proceedings.mlr.press/v202/chen23ak.html},
  abstract = 	 {Graph coarsening is a technique for solving large-scale graph problems by working on a smaller version of the original graph, and possibly interpolating the results back to the original graph. It has a long history in scientific computing and has recently gained popularity in machine learning, particularly in methods that preserve the graph spectrum. This work studies graph coarsening from a different perspective, developing a theory for preserving graph distances and proposing a method to achieve this. The geometric approach is useful when working with a collection of graphs, such as in graph classification and regression. In this study, we consider a graph as an element on a metric space equipped with the Gromovâ€“Wasserstein (GW) distance, and bound the difference between the distance of two graphs and their coarsened versions. Minimizing this difference can be done using the popular weighted kernel $K$-means method, which improves existing spectrum-preserving methods with the proper choice of the kernel. The study includes a set of experiments to support the theory and method, including approximating the GW distance, preserving the graph spectrum, classifying graphs using spectral information, and performing regression using graph convolutional networks. Code is available at https://github.com/ychen-stat-ml/GW-Graph-Coarsening.}
}

@article{vayer2023controlling,
  title={Controlling Wasserstein distances by Kernel norms with application to Compressive Statistical Learning},
  author={Vayer, Titouan and Gribonval, R{\'e}mi},
  journal={Journal of Machine Learning Research},
  volume={24},
  number={149},
  pages={1--51},
  year={2023}
}

@article{canas2012learning,
  title={Learning probability measures with respect to optimal transport metrics},
  author={Canas, Guillermo and Rosasco, Lorenzo},
  journal={Advances in Neural Information Processing Systems},
  volume={25},
  year={2012}
}

@article{peyre2019computational,
  title={Computational optimal transport: With applications to data science},
  author={Peyr{\'e}, Gabriel and Cuturi, Marco and others},
  journal={Foundations and Trends in Machine Learning},
  volume={11},
  number={5-6},
  pages={355--607},
  year={2019},
  publisher={Now Publishers, Inc.}
}

@article{van2024distributional,
  title={Distributional Reduction: Unifying Dimensionality Reduction and Clustering with Gromov-Wasserstein Projection},
  author={Van Assel, Hugues and Vincent-Cuaz, C{\'e}dric and Courty, Nicolas and Flamary, R{\'e}mi and Frossard, Pascal and Vayer, Titouan},
  journal={arXiv preprint arXiv:2402.02239},
  year={2024}
}